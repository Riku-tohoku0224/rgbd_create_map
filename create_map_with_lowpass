#!/usr/bin/env python3

import rospy
import ros_numpy
import message_filters
from sensor_msgs.msg import Image, PointCloud2
from geometry_msgs.msg import PoseStamped, Point
import sensor_msgs.point_cloud2 as pc2
from cv_bridge import CvBridge
import open3d as o3d
import numpy as np
from std_msgs.msg import Header, ColorRGBA
import cv2
from visualization_msgs.msg import Marker
from scipy.spatial.transform import Rotation as R
import matplotlib.pyplot as plt

def create_transformation_matrix():
    angle = np.deg2rad(15)  # Convert 15 degrees to radians
    rotation = R.from_euler('y', angle).as_matrix()
    
    T = np.eye(4)
    T[:3, :3] = rotation
    
    return T

def create_transformation_matrix_x_negative_15_degrees():
    angle = np.deg2rad(-15)  # Convert -15 degrees to radians
    rotation = R.from_euler('x', angle).as_matrix()  # Generate rotation matrix around the x-axis
    
    T = np.eye(4)  # Create a 4x4 identity matrix
    T[:3, :3] = rotation  # Apply the rotation matrix
    
    return T

tottori_map = o3d.geometry.PointCloud()
camera_positions = []
callback_counter = 0

def pose_to_matrix(pose_stamped):
    pose = pose_stamped.pose
    quaternion = [pose.orientation.x, pose.orientation.y, pose.orientation.z, pose.orientation.w]
    translation = [pose.position.x, pose.position.y, pose.position.z]
    rotation = R.from_quat(quaternion).as_matrix()

    return rotation, translation

def create_marker(points, frame_id):
    marker = Marker()
    marker.header.frame_id = frame_id
    marker.header.stamp = rospy.Time.now()
    marker.ns = "trajectory"
    marker.id = 0
    marker.type = Marker.LINE_STRIP
    marker.action = Marker.ADD
    marker.scale.x = 0.05
    marker.color = ColorRGBA(1.0, 0.0, 0.0, 1.0)

    # Apply transformation matrix for -15 degree rotation around the x-axis
    T = create_transformation_matrix_x_negative_15_degrees()
    for point in points:
        p = np.array([point[0], point[1], point[2], 1])
        p_transformed = T @ p  # Apply the transformation matrix
        marker_point = Point()
        marker_point.x = p_transformed[2]
        marker_point.y = -p_transformed[0]
        marker_point.z = -p_transformed[1]
        marker.points.append(marker_point)
    
    return marker

def apply_low_pass_filter_to_point_cloud(pcd, resolution=0.03, filter_size=5):
    points = np.asarray(pcd.points)
    x_data, y_data, z_data = points[:, 0], points[:, 1], points[:, 2]

    x_edges = np.arange(x_data.min(), x_data.max() + resolution, resolution)
    y_edges = np.arange(y_data.min(), y_data.max() + resolution, resolution)

    z_grid = np.full((len(x_edges) - 1, len(y_edges) - 1, 2), np.nan)
    for i in range(len(x_data)):
        x_idx = np.searchsorted(x_edges, x_data[i]) - 1
        y_idx = np.searchsorted(y_edges, y_data[i]) - 1
        if np.isnan(z_grid[x_idx, y_idx, 0]) or abs(z_data[i]) > abs(z_grid[x_idx, y_idx, 0]):
            z_grid[x_idx, y_idx, 0] = z_data[i]
            z_grid[x_idx, y_idx, 1] = 1

    z_grid[np.isnan(z_grid[:, :, 0]), 1] = 1

    rows, cols, _ = z_grid.shape
    f = np.fft.fft2(np.nan_to_num(z_grid[:,:,0]))
    fshift = np.fft.fftshift(f)

    crow, ccol = int(rows / 2), int(cols / 2)
    mask = np.zeros((rows, cols), np.uint8)
    for i in range(rows):
        for j in range(cols):
            if (i - crow)**2 + (j - ccol)**2 <= filter_size**2:
                mask[i, j] = 1

    fshift_masked = fshift * mask

    non_zero_before = np.count_nonzero(fshift)
    non_zero_after = np.count_nonzero(fshift_masked)

    print(f"Data size in frequency domain before filtering: {non_zero_before}")
    print(f"Data size in frequency domain after filtering : {non_zero_after}")

    return fshift_masked, x_edges, y_edges, z_grid

def regenerate_point_cloud(fshift_masked, x_edges, y_edges, z_grid):
    f_ishift = np.fft.ifftshift(fshift_masked)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.real(img_back)

    filtered_z_grid = np.zeros_like(z_grid)
    filtered_z_grid[:,:,0] = img_back
    filtered_z_grid[:,:,1] = z_grid[:,:,1]

    # マスクを使って新しい点群を再生成
    mask = filtered_z_grid[:,:,1].ravel() == 1
    x_centers = (x_edges[:-1] + x_edges[1:]) / 2
    y_centers = (y_edges[:-1] + y_edges[1:]) / 2
    x_coords, y_coords = np.meshgrid(x_centers, y_centers, indexing='ij')

    new_points = np.vstack((x_coords.ravel()[mask], y_coords.ravel()[mask], filtered_z_grid[:,:,0].ravel()[mask])).T

    filtered_pcd = o3d.geometry.PointCloud()
    filtered_pcd.points = o3d.utility.Vector3dVector(new_points)

    return filtered_pcd


def images_callback(color_img, depth_img, camera_pose_stamped, pub, marker_pub, frame_id):
    global callback_counter
    callback_counter += 1

    rospy.loginfo("同期した画像とカメラのポーズを受信")
    bridge = CvBridge()
    try:
        header = Header()
        header.stamp = rospy.Time.now()
        header.frame_id = frame_id

        cv_color_img = bridge.imgmsg_to_cv2(color_img, "bgr8")
        cv_depth_img = bridge.imgmsg_to_cv2(depth_img, desired_encoding="passthrough")
        cv_depth_img = cv2.resize(cv_depth_img, (640, 480), interpolation=cv2.INTER_NEAREST)
        cv_depth_img = np.array(cv_depth_img, dtype=np.float32) / 1000.0

        color_raw = o3d.geometry.Image(cv_color_img)
        depth_raw = o3d.geometry.Image(cv_depth_img)
        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(
            color_raw, depth_raw, depth_scale=1.0, depth_trunc=3.0, convert_rgb_to_intensity=False
        )

        intrinsic = o3d.camera.PinholeCameraIntrinsic(
            640, 480, 616.5249633789062, 616.7235717773438, 331.1578674316406, 234.31881713867188
        )
        # RGBD画像から点群を生成
        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, intrinsic)

        # 点群をNumpy配列に変換
        points = np.asarray(pcd.points)
        rospy.loginfo(f"Generated point cloud shape: {points.shape}")

        # open3d系からros系に変換するための行列
        R1 = np.array([[0, 0, 1],
                       [-1, 0, 0],
                       [0, -1, 0]])

        # カメラの姿勢の行列を取得
        T_rotation, T_translation = pose_to_matrix(camera_pose_stamped)
        points = (np.dot(T_rotation, points.T).T + T_translation)
        # ros系からopen3d系に戻す
        points = np.dot(R1, points.T).T

        # 変換された点群をOpen3Dの点群オブジェクトに変換
        pcd.points = o3d.utility.Vector3dVector(points)
        rospy.loginfo(f"Transformed point cloud shape: {points.shape}")

        camera_angle_matrix = create_transformation_matrix()
        pcd.transform(camera_angle_matrix)

        # ローパスフィルタの適用
        fshift_masked, x_edges, y_edges, z_grid = apply_low_pass_filter_to_point_cloud(pcd, resolution=0.03, filter_size=5)
        pcd = regenerate_point_cloud(fshift_masked, x_edges, y_edges, z_grid)
        rospy.loginfo(f"Filtered point cloud shape: {np.asarray(pcd.points).shape}")

        global tottori_map
        global camera_positions

        # tottori_mapに点群を追加
        tottori_map += pcd

        # カメラ位置を追加
        camera_positions.append([camera_pose_stamped.pose.position.x,
                                 camera_pose_stamped.pose.position.y,
                                 camera_pose_stamped.pose.position.z])
        marker = create_marker(camera_positions, frame_id)
        marker_pub.publish(marker)

        # ログ出力
        rospy.loginfo(f"ボクセルダウンサンプリング後の点群には {len(tottori_map.points)} 点")

        # 20回ごとにPointCloud2メッセージをpublishし、.pcdファイルとして保存
        if callback_counter % 20 == 0:
            points = np.asarray(tottori_map.points)

            pc_array = np.zeros(len(points), dtype=[('x', np.float32), ('y', np.float32), ('z', np.float32)])
            pc_array['x'] = points[:, 0]
            pc_array['y'] = points[:, 1]
            pc_array['z'] = points[:, 2]

            pc_msg = ros_numpy.msgify(PointCloud2, pc_array, stamp=header.stamp, frame_id=header.frame_id)
            pub.publish(pc_msg)
            rospy.loginfo(f"PointCloud2メッセージを {len(points)} 点で公開")

            # 点群を .pcd ファイルとして保存
            # pcd_file_path = f"/home/riku-suzuki/python_tutorial/tottori_map_{callback_counter//20}.pcd"
            # o3d.io.write_point_cloud(pcd_file_path, tottori_map)
            # rospy.loginfo(f"点群を {pcd_file_path} に保存")

    except Exception as e:
        rospy.logerr(f"処理に失敗: {e}")



def listener():
    rospy.init_node('create_dense_map', anonymous=False)
    pub = rospy.Publisher('/tottori_map_point_cloud', PointCloud2, queue_size=10)
    marker_pub = rospy.Publisher('/camera_trajectory', Marker, queue_size=10)
    frame_id = "map"

    color_sub = message_filters.Subscriber("/camera/color/image_raw", Image)
    depth_sub = message_filters.Subscriber("/camera/depth/image_rect_raw", Image)
    pose_sub = message_filters.Subscriber("/orb_slam3/camera_pose", PoseStamped)

    ts = message_filters.ApproximateTimeSynchronizer([color_sub, depth_sub, pose_sub], 10, 0.05)
    ts.registerCallback(lambda color, depth, pose_stamped: images_callback(color, depth, pose_stamped, pub, marker_pub, frame_id))

    rospy.spin()

if __name__ == '__main__':
    try:
        listener()
    except rospy.ROSInterruptException:
        pass
